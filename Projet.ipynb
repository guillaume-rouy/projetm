{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit ('base': conda)",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "51ca20ebe4d9f4c9bea280f97ee9cbe972c8b10e983d99e82a066eabf95f65e8"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliothèques \n",
    "# Autograd & Numpy\n",
    "import autograd\n",
    "import autograd.numpy as np\n",
    "\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 10] # [width, height] (inches). \n",
    "\n",
    "# Jupyter & IPython\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Définition du gradient \n",
    "def grad(f):\n",
    "    g = autograd.grad\n",
    "    def grad_f(x, y):\n",
    "        return np.array([g(f, 0)(x, y), g(f, 1)(x, y)])\n",
    "    return grad_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Définition de la Jacobienne\n",
    "def J(f):\n",
    "    j = autograd.jacobian\n",
    "    def J_f(x, y):\n",
    "        return np.array([j(f, 0)(x, y), j(f, 1)(x, y)]).T\n",
    "    return J_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implémentation de display_contour \n",
    "def display_contour(f, x, y, levels):\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = f(X, Y)\n",
    "    fig, ax = plt.subplots()\n",
    "    contour_set = plt.contour(\n",
    "        X, Y, Z, colors=\"grey\", linestyles=\"dashed\", \n",
    "        levels=levels \n",
    "    )\n",
    "    ax.clabel(contour_set)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"$x_1$\") \n",
    "    plt.ylabel(\"$x_2$\")\n",
    "    plt.gca().set_aspect(\"equal\")"
   ]
  },
  {
   "source": [
    "### Fonctions quadratiques "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x1, x2):\n",
    "    x1 = np.array(x1)\n",
    "    x2 = np.array(x2)\n",
    "    return 3.0 * x1 * x1 - 2.0 * x1 * x2 + 3.0 * x2 * x2 "
   ]
  },
  {
   "source": [
    "### Question 1\n",
    "\n",
    "On a posé $c \\in \\mathbb{R}$, supposé la fonction $f:\\mathbb{R}^2 \\to \\mathbb{R}$ continue, et telle que\n",
    "$f(x_1, x_2) \\to +\\infty$ quand $\\|(x_1,x_2)\\| \\to +\\infty$.\n",
    "\n",
    "Premièrement, l'ensemble de niveau $c$ de $f$ est un ensemble fermé car c'est l'image réciproque de l'ensemble fermé $\\{c\\}$ par une fonction continue. De plus, l'ensemble de niveau $c$ est borné donc c'est un compact car nous sommes en dimension finie. \n",
    "\n",
    "On a également l'équivalence entre les enoncés :\n",
    "\n",
    "$(i)$ L'ensemble de niveau $c$ est non vide\n",
    "\n",
    "$(ii)$ $c \\ge  \\underset{(x_1,x_2) \\in \\mathbb{R^{2}}}{\\text{inf}} f(x_1,x_2)$ (Cette borne inférieure est atteinte.)\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 2\n",
    "Au voisinage du point $x_0 = \\begin{pmatrix} x_{10} \\\\x_{20}\\\\\\end{pmatrix} \\in \\mathbb{R}^2$ où le gradient de $f$ ne s'annule pas, on pose :\n",
    "$$\n",
    "p(x_1, x_2) := \\frac{\\partial_2 f(x_0)}{\\|\\nabla f(x_0)\\|} (x_1 - x_{10}) -\n",
    "\\frac{\\partial_1 f(x_0)}{\\|\\nabla f(x_0)\\|} (x_2 - x_{20}).\n",
    "$$\n",
    "\n",
    "On cherche à interpréter géométriquement cette fonction $p$.\n",
    "\n",
    "On sait que le vecteur gradient évalué en $x_0$ $\\nabla f(x_0)$ est normal à la courbe de niveau en $x_0$. Ainsi, on peut former une base orthonormée en posant un vecteur normal $\\overrightarrow{n}$ et un vecteur tangent $\\overrightarrow{\\tau}$ à la courbe de niveau en $x_0$ de la manière suivante :\n",
    "\n",
    "$$\n",
    "\\overrightarrow{n}=\\frac{1}{\\|\\nabla f(x_0)\\|}\n",
    "\\begin{pmatrix}\n",
    "\\partial_1 f(x_0) \\\\\n",
    " \\partial_2 f(x_0)\\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\overrightarrow{\\tau}=\\frac{1}{\\|\\nabla f(x_0)\\|}\n",
    "\\begin{pmatrix}\n",
    "\\partial_2 f(x_0) \\\\\n",
    " -\\partial_1 f(x_0)\\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "On se préoccupe maintenant d'un vecteur $x=\\begin{pmatrix} x_1 \\\\x_2\\\\\\end{pmatrix}$. On remarque que $p(x)$ n'est rien d'autre que le produit scalaire entre le vecteur $x-x_0$ et le vecteur tangentiel $\\overrightarrow{\\tau}$. Autrement dit, $p(x)$ est la projection du vecteur $x-x_0$ sur la tangente à la courbe de niveau en $x_0$. En effet :\n",
    "\n",
    "$$\n",
    "\\left\\langle x-x_0  |  \\overrightarrow{\\tau} \\right\\rangle = \\frac{\\partial_2 f(x_0)}{\\|\\nabla f(x_0)\\|} (x_1 - x_{10}) -\n",
    "\\frac{\\partial_1 f(x_0)}{\\|\\nabla f(x_0)\\|} (x_2 - x_{20})\n",
    "$$\n",
    "\n",
    "Et ainsi :\n",
    "\n",
    "$$\n",
    "p(x)=\\left\\langle x-x_0  |  \\overrightarrow{\\tau} \\right\\rangle\n",
    "$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Implémentation python de la fonction p\n",
    "\n",
    "def p(f,x10 ,x20 ,x1 ,x2 ):\n",
    "    '''Implémentation Python de la fonction p.\n",
    "    f : fonction en question\n",
    "    x10, x20 : coordonnées du point x0\n",
    "    x1, x2 : coordonnées d'évaluation de la fonction p'''\n",
    "    grad_f = grad(f)\n",
    "    gradx0= grad_f(x10,x20)\n",
    "    d1=gradx0[0]\n",
    "    d2=gradx0[1]\n",
    "    norme=(d1*d1+d2*d2)**(1/2)\n",
    "    return (d2*(x1-x10)/norme) - (d1*(x2-x20)/norme)\n",
    "\n",
    "def affichage3d():\n",
    "    fig=plt.figure()\n",
    "    ax=fig.gca(projection='3d')\n",
    "    x = np.linspace(-10,10.0,100)\n",
    "    X, Y = np.meshgrid(x, x)\n",
    "    Z = p(f1,1.0,1.0,X, Y)\n",
    "    W = f1(X,Y)\n",
    "    surf = ax.plot_surface(X,Y,Z)\n",
    "    board = ax.plot_surface(X,Y,W)\n",
    "    plt.show()\n"
   ]
  },
  {
   "source": [
    "### Question 3\n",
    "On pose:\n",
    "\n",
    "$$\n",
    "g : (x,t) \\in  \\mathbb{R^2}\\times \\mathbb{R} \\mapsto \\begin{pmatrix}\n",
    "f(x) - c \\\\\n",
    "p(x) - t\n",
    "\\end{pmatrix}\\in \\mathbb{R^2}\n",
    "$$\n",
    " - g est continûment différentiable : \n",
    "$$ \n",
    "  J_g=\\begin{pmatrix}\n",
    "\\partial_1 g_1 &\\partial_2 g_1  & \\partial_3 g_1  \\\\\n",
    " \\partial_1 g_2& \\partial_2 g_2 & \\partial_3 g_2\n",
    "\\end{pmatrix}\n",
    "= \\begin{pmatrix}\n",
    "\\partial_1 f & \\partial_2 f & 0 \\\\\n",
    " \\frac{\\partial_2 f(x_0)}{\\|\\nabla f(x_0)\\|}& -\\frac{\\partial_1 f(x_0)}{\\|\\nabla f(x_0)\\|}  & -1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    " Effectivement, les dérivées partielles de $g_1$ et $g_2$ existent et sont continue car $f$ est elle même continûment différentiable.\n",
    "\n",
    "\n",
    " - Inversibilité de $\\partial_x g$:\n",
    " \n",
    "\n",
    "$$\n",
    "\\partial_x g(x,t) = \\begin{pmatrix}\n",
    "\\partial_1f &\\partial_2f  \\\\\n",
    "\\frac{\\partial_2 f(x_0)}{\\|\\nabla f(x_0)\\|}& -\\frac{\\partial_1 f(x_0)}{\\|\\nabla f(x_0)\\|} \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "D'où:\n",
    "\n",
    "\n",
    "$$\n",
    "det (\\partial_x g(x,t)) = - \\frac{\\partial_2 f(x_0)}{\\|\\nabla f(x_0)\\|}\\partial_1f(x) - \\frac{\\partial_2 f(x_0)}{\\|\\nabla f(x_0)\\|}\\partial_2f(x)\n",
    "$$\n",
    "\n",
    "Donc :\n",
    "\n",
    "$$\n",
    "\\forall t \\in \\mathbb{R}, det (\\partial_x g(x_0,t))= - \\|\\nabla f(x_0)\\| \\neq 0\n",
    "\\\n",
    "\\\n",
    "$$\n",
    "\n",
    "\n",
    "Ainsi, par continuité du déterminant, il existe $Q$ un voisinage de $x_0$ dans lequel $\\partial_x g(x,t)$ est inversible pour tout t. Ainsi, il existe un ouvert  $W = Q \\times \\mathbb{R}$, tel que $\\partial_xg$ soit inversible. \n",
    "\n",
    "Par le théorème des fonctions implicites il existe donc des voisinages ouverts $U$ de $x_0$ et V de $0$ tel que $0 = p(x_0)$, tels que $U \\times V \\subset W$ et une unique fonction $\\gamma : V \\to \\mathbb{R^2}$ continûment différentiable telle que $\\forall t \\in V$ et $\\forall x \\in U$ :\n",
    "\n",
    "\n",
    "$$\n",
    "g(x,t)=0 \\Leftrightarrow \n",
    "x = \\gamma (t) = \\gamma(p(x))\n",
    "$$\n",
    "\n",
    "Nous obtenons donc qu'il existe un $\\varepsilon > 0$ et une fonction (continûment différentiable) $\\gamma :\\left]-\\varepsilon,\\varepsilon \\right[ \\to \\mathbb{R}^2$  ($\\left]-\\varepsilon,\\varepsilon \\right[$ est un voisinage de 0) tels que dans un voisinage ouvert de $x_0,$ :\n",
    "$$\n",
    "f(x_1,x_2) = c \\Leftrightarrow  (x_1, x_2) = \\gamma(t) \\ où \\ t = p(x_1, x_2)\n",
    "$$\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 4\n",
    "\n",
    "Il s'agit d'étudier le vecteur $\\gamma'(t)$. L'application du théorème des fonctions implicites donnne également :\n",
    "\n",
    "$$\n",
    "\\gamma'(t) = d\\gamma (t) = - (\\partial_x g(x,t))^{-1} \\cdot \\partial_t g(x,t)\n",
    "$$\n",
    "\n",
    "Les calculs précédants permettent alors d'écrire :\n",
    "\n",
    "$$\n",
    "\\gamma'(t) = - \\frac{1}{det(\\partial_x g(x,t))}\n",
    "\\begin{pmatrix}\n",
    "-\\frac{\\partial_1 f(x_0)}{\\|\\nabla f(x_0)\\|} & -\\partial_2 f(x) \\\\\n",
    "- \\frac{\\partial_2 f(x_0)}{\\|\\nabla f(x_0)\\|} & \\partial_1 f(x) \\\\\n",
    "\\end{pmatrix}\n",
    "\n",
    "\\begin{pmatrix}\n",
    "0 \\\\\n",
    "-1 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\gamma'(t) = \\frac{1}{det(\\partial_x g(x,t))}\n",
    "\\begin{pmatrix}\n",
    "-\\partial_2 f(x) \\\\\n",
    "\\partial_1 f(x)  \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Comme le gradient de $f$ est non-nul dans voisinage de $x_0$, on en déduit que le vecteur $\\gamma'(t)$ est non nul sur ce même voisinage, c'est à dire le voisinage $V=\\left] -\\varepsilon; \\varepsilon\\right[$ introduit à la question précédente. Par ailleurs, le vecteur $\\gamma'(t)$ est proportionnel au vecteur $\\overrightarrow{\\tau}$ tangent à la courbe, et est donc orthogonal au vecteur gradient $\\Delta f(x_0)$.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 5\n",
    "\n",
    "Nous choisissons $\\varepsilon = 2^{-52}$ car il s'agit de la plus petite différence entre des doubles détectable par l'ordinateur (epsilon machine)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "N = 100\n",
    "eps = 0.01"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 33,
   "outputs": []
  },
  {
   "source": [
    "### Tâche 1\n",
    "Implémentation python de la recherche de zéro par méthode de Newton pour une fonction $F:\\mathbb{R}^{2}\\longrightarrow \\mathbb{R}^{2}$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Newton(F, x0, y0, eps=eps, N=N):\n",
    "    x,y=x0,y0\n",
    "    X=np.array([x,y])\n",
    "    J_F = J(F)\n",
    "    for i in range(N):\n",
    "        inv = np.linalg.inv(J_F(x,y))\n",
    "        X = X - inv.dot(F(x,y))\n",
    "        x,y = X[0], X[1]\n",
    "        if np.sqrt((x - x0)**2 + (y - y0)**2) <= eps:\n",
    "            return x, y\n",
    "        x0, y0 = x, y\n",
    "    else:\n",
    "        raise ValueError(f\"no convergence in {N} steps.\")"
   ]
  },
  {
   "source": [
    "### Tâche 2\n",
    "\n",
    "On définit la fonction: \n",
    "\n",
    "$$\n",
    "f_{11} : (x_1,x_2) \\in  \\mathbb{R^2} \\mapsto \n",
    "\\begin{pmatrix}\n",
    "f_1(x_1,x_2) \\\\x_1-x_2\n",
    "\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Lorsque $f$ s'annule, on a alors $x_1 = x_2$.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(0.00625, 0.00625)\n"
     ]
    }
   ],
   "source": [
    "def f11(x1,x2):\n",
    "    f11 = np.array([f1(x1,x2), x1-x2])\n",
    "    return f11\n",
    "\n",
    "X = Newton(f11, 0.8, 0.8, eps = eps, N=N)\n",
    "print (X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}